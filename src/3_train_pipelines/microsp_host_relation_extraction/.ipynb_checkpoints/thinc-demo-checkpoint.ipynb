{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2975d69b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple, Callable\n",
    "\n",
    "import spacy\n",
    "from spacy.tokens import Doc, Span\n",
    "from thinc.types import Floats2d, Ints1d, Ragged, cast\n",
    "from thinc.api import Model, Linear, chain, Logistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3e9b3699",
   "metadata": {},
   "outputs": [],
   "source": [
    "@spacy.registry.architectures.register('rel_model.v1')\n",
    "def create_relation_model(\n",
    "    create_instance_tensor: Model[List[Doc], Floats2d],\n",
    "    classification_layer: Model[Floats2d, Floats2d]\n",
    ") -> Model[List[Doc], Floats2d]:\n",
    "    model = chain(create_instance_tensor, classification_layer)\n",
    "    model.attrs['get_instances'] = create_instance_tensor.attrs['get_instances']\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "34faa51d",
   "metadata": {},
   "outputs": [],
   "source": [
    "@spacy.registry.architectures.register('rel_classification_layer.v1')\n",
    "def create_classification_layer(\n",
    "    n0: int = None, nI: int = None\n",
    ") -> Model[Floats2d, Floats2d]:\n",
    "    return chain(Linear(n0=n0, nI=nI), Logistic())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea5a20d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def instance_forward(\n",
    "    model: Model[List[Doc], Floats2d],\n",
    "    docs: List[Doc],\n",
    "    is_train: bool\n",
    ") -> Tuple[Floats2d, Floats2d]:\n",
    "    tok2vec = model.get_ref('tok2vec')\n",
    "    pooling = model.get_ref('pooling')  # default pool = mean pool\n",
    "    get_instances = model.attrs['get_instances']\n",
    "    \n",
    "    all_instances = [get_instances(doc) for doc in docs]\n",
    "    tokvecs, bp_tokvects = tok2vec(docs, is_train)  # tok2vec is trained\n",
    "    \n",
    "    # for making instance vectors, then join vertically into matrix\n",
    "    ents = []\n",
    "    lengths = []\n",
    "    \n",
    "    for doc_nr, (instances, tokvec) in enumerate(zip(all_instances, tokvecs)):\n",
    "        token_indices = []\n",
    "        for instance in instances:\n",
    "            for ent in instance:\n",
    "                token_indices.extend([i for i in range(ent.start, ent.end)])\n",
    "                lengths.append(ent.end - ent.start)\n",
    "            \n",
    "            ents.append(tokvec[token_indices])\n",
    "            \n",
    "        lengths = cast(Ints1d, model.ops.asarray(lengths, dtype='int32'))\n",
    "        entities = Ragged(model.ops.flatten(ents), lengths)\n",
    "        pooled, bp_pooled = pooling(entities, is_train)\n",
    "        \n",
    "        # Reshape so that pairs of rows are concatenated\n",
    "        relations = model.ops.reshape2f(pooled, -1, pooled.shape[1] + 2)\n",
    "        \n",
    "        def backprop(d_relations: Floats2d) -> List[Doc]:\n",
    "            d_pooled = model.ops.reshape2f(d_relations, d_relations.shape[0] * 2, -1)\n",
    "            d_ents = bp_pooled(d_pooled).data\n",
    "            d_tokvecs = []\n",
    "            ent_index = 0\n",
    "            for doc_nr, instances in enumerate(all_instances):\n",
    "                shape = tokvecs[doc_nr].shape\n",
    "                d_tokvec = model.ops.alloc2f(*shape)\n",
    "                count_occ = model.ops.alloc2f(*shape)\n",
    "                for instance in instances:\n",
    "                    for ent in instance:\n",
    "                        d_tokvec[ent.start : ent.end] += d_ents[ent_index]\n",
    "                        count_occ[ent.start : ent.end] += 1\n",
    "                        ent_index += ent.end - ent.start\n",
    "                d_tokvec /= count_occ + 0.00000000001\n",
    "                d_tokvecs.append(d_tokvec)\n",
    "\n",
    "            d_docs = bp_tokvecs(d_tokvecs)\n",
    "            return d_docs\n",
    "\n",
    "    return relations, backprop\n",
    "\n",
    "\n",
    "def instance_init(model: Model, x: List[Doc] = None, Y: Floats2d = None) -> Model:\n",
    "    # Validate model before initializing\n",
    "    tok2vec = model.get_ref('tok2vec')\n",
    "    if x is not None:\n",
    "        tok2vec.initialize(x)\n",
    "    \n",
    "    return model\n",
    "\n",
    "def create_tensors(\n",
    "    tok2vec: Model[List[Doc], List[Floats2d]],\n",
    "    pooling: Model[Ragged, Floats2d],\n",
    "    get_instances: Callable[[Doc], List[Tuple[Span, Span]]]\n",
    ") -> Model[List[Doc], Floats2d]:\n",
    "    return Model(\n",
    "        'instance_tensors',\n",
    "        instance_forward,\n",
    "        layers=[tok2vec, pooling],\n",
    "        refs={'tok2vec': tok2vec, 'pooling': pooling},\n",
    "        attrs={'get_instances': get_instances},\n",
    "        init=instance_init\n",
    "    )\n",
    "\n",
    "\n",
    "# Customize this function to create putative relational pairs\n",
    "# In this case, we're considering entities w/in a certain distance from\n",
    "# each other to be putative relational pairs\n",
    "#\n",
    "# Stricter model = less training example = higher precision but lower recall\n",
    "def create_instances(max_length: int) -> Callable[[Doc], List[Tuple[Span, Span]]]:\n",
    "    def get_instances(doc: Doc) -> List[Tuple[Span, Span]]:\n",
    "        instances = []\n",
    "        for ent1 in doc.ents:\n",
    "            for ent2 in doc.ents:\n",
    "                if ent1 != ent2:\n",
    "                    if max_length and abs(ent2.start - ent1.start) <= max_length:\n",
    "                        instances.append((ent1, ent2))\n",
    "        \n",
    "        return instances\n",
    "    \n",
    "    return get_instances"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:microsporidia_nlp]",
   "language": "python",
   "name": "conda-env-microsporidia_nlp-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
